{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m3/qbgnh0_515zfmw0lh3yrrpxh0000gn/T/ipykernel_15443/4181704131.py:14: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(audio_file, sr=None)\n",
      "/Users/sunnytamang/Documents/Research_Papers/Music_Genre_Classification/music_genre_classification/lib/python3.9/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /Users/sunnytamang/Documents/Research_Papers/Music_Genre_Classification/data_dir/genres_original/jazz/jazz.00054.wav due to feature extraction error.\n",
      "Total Number of Entries: 999\n",
      "X Shape after Concatenation: (999, 16809)\n",
      "y Shape after Concatenation: (999,)\n",
      "SVM Accuracy: 0.575\n",
      "Random Forest Accuracy: 0.5\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 7s 249ms/step - loss: 13.0027 - accuracy: 0.2053 - val_loss: 1.6868 - val_accuracy: 0.4000\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 6s 241ms/step - loss: 1.5244 - accuracy: 0.4656 - val_loss: 1.5589 - val_accuracy: 0.4200\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 6s 247ms/step - loss: 1.0642 - accuracy: 0.6145 - val_loss: 1.1986 - val_accuracy: 0.5750\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 6s 240ms/step - loss: 0.5271 - accuracy: 0.8461 - val_loss: 1.2436 - val_accuracy: 0.5650\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 6s 245ms/step - loss: 0.1820 - accuracy: 0.9474 - val_loss: 1.4699 - val_accuracy: 0.6350\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 6s 251ms/step - loss: 0.0639 - accuracy: 0.9850 - val_loss: 1.6753 - val_accuracy: 0.5350\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 6s 249ms/step - loss: 0.0467 - accuracy: 0.9937 - val_loss: 1.7442 - val_accuracy: 0.6150\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 6s 250ms/step - loss: 0.0178 - accuracy: 0.9962 - val_loss: 1.4375 - val_accuracy: 0.6650\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 6s 250ms/step - loss: 0.0146 - accuracy: 0.9987 - val_loss: 1.6543 - val_accuracy: 0.6250\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 6s 248ms/step - loss: 0.0125 - accuracy: 0.9975 - val_loss: 1.8770 - val_accuracy: 0.6300\n",
      "7/7 [==============================] - 0s 54ms/step - loss: 1.8770 - accuracy: 0.6300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunnytamang/Documents/Research_Papers/Music_Genre_Classification/music_genre_classification/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Accuracy: 0.6299999952316284\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Function for extracting features from audio files\n",
    "def extract_features(audio_file):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_file, sr=None)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "\n",
    "        # this is to fix lenght of the mfcc as 1 element has mfcc size to be (13, 1299) and rest were (13, 1293)\n",
    "        mfccs = librosa.util.fix_length(mfccs, size=1293, axis=1)\n",
    "\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        zero_crossing_rate = librosa.feature.zero_crossing_rate(y)\n",
    "        # print({\n",
    "        #     'mfccs': mfccs,\n",
    "        #     'spectral_centroid': spectral_centroid,\n",
    "        #     'zero_crossing_rate': zero_crossing_rate\n",
    "        # })\n",
    "        return {\n",
    "            'mfccs': mfccs,\n",
    "            'spectral_centroid': spectral_centroid,\n",
    "            'zero_crossing_rate': zero_crossing_rate\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "genre_to_label = {'blues':0,'classical':1, 'country':2, 'disco':3, 'hiphop':4, 'jazz':5, 'metal':6, 'pop':7, 'reggae':8, 'rock':9}\n",
    "# Function to load preprocessed data\n",
    "def load_preprocessed_data(dataset_path='your_dataset_path'):\n",
    "    extracted_features = []\n",
    "\n",
    "    for genre_label in os.listdir(dataset_path):\n",
    "        genre_path = os.path.join(dataset_path, genre_label)\n",
    "\n",
    "        if not os.path.isdir(genre_path):\n",
    "            continue\n",
    "\n",
    "        # Check if the genre label is in the mapping\n",
    "        if genre_label in genre_to_label:\n",
    "            label = genre_to_label[genre_label]\n",
    "\n",
    "            for audio_file in os.listdir(genre_path):\n",
    "                if audio_file.endswith(\".wav\"):\n",
    "                    audio_file_path = os.path.join(genre_path, audio_file)\n",
    "                    features = extract_features(audio_file_path)\n",
    "\n",
    "                    # Check if features are successfully extracted\n",
    "                    if features is not None:\n",
    "                        extracted_features.append({'features': features, 'label': label})\n",
    "                    else:\n",
    "                        print(f\"Skipping {audio_file_path} due to feature extraction error.\")\n",
    "\n",
    "    return extracted_features\n",
    "\n",
    "# Function to prepare data for machine learning models\n",
    "def prepare_data(extracted_features):\n",
    "    print(f\"Total Number of Entries: {len(extracted_features)}\")\n",
    "    # Print sizes before concatenation\n",
    "    # for i, entry in enumerate(extracted_features):\n",
    "    #     print(f\"MFCCs Size for Entry {i}: {entry['features']['mfccs'].shape}\")\n",
    "\n",
    "    # X = np.concatenate([entry['features']['mfccs'] for entry in extracted_features], axis=0)\n",
    "    X = np.array([entry['features']['mfccs'].reshape(-1) for entry in extracted_features])\n",
    "    y = np.array([entry['label'] for entry in extracted_features])\n",
    "    # Print shapes after concatenation\n",
    "    print(f\"X Shape after Concatenation: {X.shape}\")\n",
    "    print(f\"y Shape after Concatenation: {y.shape}\")\n",
    "    return X, y\n",
    "\n",
    "# Function to train Support Vector Machine (SVM) model\n",
    "def train_svm(X_train, y_train, X_test, y_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    svm_model = SVC()\n",
    "    svm_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    svm_predictions = svm_model.predict(X_test_scaled)\n",
    "    svm_accuracy = np.mean(svm_predictions == y_test)\n",
    "    \n",
    "    return svm_accuracy\n",
    "\n",
    "# Function to train Random Forest model\n",
    "def train_random_forest(X_train, y_train, X_test, y_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    rf_model = RandomForestClassifier()\n",
    "    rf_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    rf_predictions = rf_model.predict(X_test_scaled)\n",
    "    rf_accuracy = np.mean(rf_predictions == y_test)\n",
    "    \n",
    "    return rf_accuracy\n",
    "\n",
    "# Function to train Convolutional Neural Network (CNN) model\n",
    "def train_cnn(X_train_cnn, y_train, X_test_cnn, y_test, num_classes):\n",
    "    cnn_model = models.Sequential()\n",
    "    cnn_model.add(layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_cnn.shape[1],1)))\n",
    "    cnn_model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    cnn_model.add(layers.Conv1D(64, kernel_size=3, activation='relu'))\n",
    "    cnn_model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    cnn_model.add(layers.Conv1D(64, kernel_size=3, activation='relu'))\n",
    "    cnn_model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    cnn_model.add(layers.Conv1D(128, kernel_size=3, activation='relu'))\n",
    "    cnn_model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    cnn_model.add(layers.Conv1D(256, kernel_size=3, activation='relu'))\n",
    "    cnn_model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    # model.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
    "    # model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    cnn_model.add(layers.Flatten())\n",
    "    cnn_model.add(layers.Dense(256, activation='relu'))\n",
    "    cnn_model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    # model = models.Sequential()\n",
    "    # model.add(layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)))\n",
    "    # model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    # model.add(layers.Flatten())\n",
    "    # model.add(layers.Dense(64, activation='relu'))\n",
    "    # model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    cnn_model.fit(X_train_cnn, y_train, epochs=10, batch_size=32, validation_data=(X_test_cnn, y_test))\n",
    "    \n",
    "    cnn_loss, cnn_accuracy = cnn_model.evaluate(X_test_cnn, y_test)\n",
    "    \n",
    "    # Assuming 'model' is your trained model\n",
    "    cnn_model.save('/Users/sunnytamang/Documents/Research_Papers/Music_Genre_Classification/models/my_audio_cnn_model.h5')\n",
    "    \n",
    "    return cnn_accuracy\n",
    "\n",
    "# Replace 'your_dataset_path' with the path to your dataset containing WAV files\n",
    "dataset_path = '/Users/sunnytamang/Documents/Research_Papers/Music_Genre_Classification/data_dir/genres_original'\n",
    "\n",
    "# Load preprocessed data\n",
    "extracted_features = load_preprocessed_data(dataset_path)\n",
    "\n",
    "# Prepare data for machine learning models\n",
    "X, y = prepare_data(extracted_features)\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Support Vector Machine (SVM) model\n",
    "svm_accuracy = train_svm(X_train, y_train, X_test, y_test)\n",
    "print(f\"SVM Accuracy: {svm_accuracy}\")\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_accuracy = train_random_forest(X_train, y_train, X_test, y_test)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy}\")\n",
    "\n",
    "# Reshape data for Convolutional Neural Network (CNN)\n",
    "X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# Train Convolutional Neural Network (CNN) model\n",
    "cnn_accuracy = train_cnn(X_train_cnn, y_train, X_test_cnn, y_test, num_classes)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model('/Users/sunnytamang/Documents/Research_Papers/Music_Genre_Classification/models/my_audio_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'extract_features' is your feature extraction function\n",
    "# 'audio_file_path' is the path to the audio file you want to test\n",
    "test_features = extract_features('/Users/sunnytamang/Downloads/Rock Party 30 Sec Intro Preview.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape if needed\n",
    "test_features_reshaped = test_features['mfccs'].reshape(1, -1)  # Adjust the shape based on your model input\n",
    "\n",
    "# Standardize if needed\n",
    "# scaler = StandardScaler()  # Assuming you used StandardScaler during training\n",
    "# test_features_scaled = scaler.transform(test_features_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "Predicted Class: 9\n"
     ]
    }
   ],
   "source": [
    "predictions = loaded_model.predict(test_features_reshaped)\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "print(f\"Predicted Class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted Genre: rock\n"
     ]
    }
   ],
   "source": [
    "# Invert the genre_mapping\n",
    "inverse_genre_mapping = {v: k for k, v in genre_to_label.items()}\n",
    "\n",
    "# Make Predictions\n",
    "predictions = loaded_model.predict(test_features_reshaped)\n",
    "predicted_class = np.argmax(predictions)\n",
    "predicted_genre = inverse_genre_mapping.get(predicted_class, 'Unknown')\n",
    "\n",
    "print(f\"Predicted Genre: {predicted_genre}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
